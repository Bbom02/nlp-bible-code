{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "실습 [9-1] N-gram 언어 모델로 문장 생성하기",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ghdvmIsv2jul",
        "colab_type": "text"
      },
      "source": [
        "## 실습 [9-1]  \n",
        "\n",
        "### 1. 실습명 : N-gram 언어 모델로 문장 생성하기\n",
        "### 2. 실습 목적 및 설명\n",
        " \n",
        "*   파이썬의 NLTK 패키지를 이용하여 N-gram 언어 모델을 구축한다\n",
        "*   네이버에서 오픈 소스로 제공하는 nsmc 영화 리뷰 데이터셋을 이용해 문장을 생성한다.\n",
        "\n",
        "### 3. 관련 장(챕터) : 9.2.2 N-gram 언어 모델 (N-gram Language Model)\n",
        "### 4. 코드"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ex4VLpId3e-T",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import nltk\n",
        "from nltk.util import ngrams\n",
        "from nltk import word_tokenize\n",
        "from nltk import ConditionalFreqDist\n",
        "from nltk.probability import ConditionalProbDist, MLEProbDist\n",
        "import numpy as np\n",
        "import codecs\n",
        "from tqdm import tqdm\n",
        "import random"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5wazYRi07LIj",
        "colab_type": "code",
        "outputId": "b408ddd5-fe6c-4fcc-dc44-933ab069b2cc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# 한국어 처리에 필요한 konlpy 패키지를 설치하기 전에 선행 파일을 설치한다. \n",
        "!apt-get update\n",
        "\n",
        "!apt-get install g++ openjdk-8-jdk python-dev python3-dev\n",
        "\n",
        "!pip3 install JPype1-py3\n",
        "\n",
        "!pip3 install konlpy\n",
        "\n",
        "!JAVA_HOME=\"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
        "\n",
        "from konlpy.tag import Okt"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\r0% [Working]\r            \rGet:1 https://cloud.r-project.org/bin/linux/ubuntu bionic-cran35/ InRelease [3,626 B]\n",
            "Ign:2 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  InRelease\n",
            "Ign:3 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  InRelease\n",
            "Hit:4 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  Release\n",
            "Hit:5 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  Release\n",
            "Hit:6 http://archive.ubuntu.com/ubuntu bionic InRelease\n",
            "Hit:7 http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu bionic InRelease\n",
            "Get:8 http://security.ubuntu.com/ubuntu bionic-security InRelease [88.7 kB]\n",
            "Get:10 https://cloud.r-project.org/bin/linux/ubuntu bionic-cran35/ Packages [75.1 kB]\n",
            "Get:11 http://archive.ubuntu.com/ubuntu bionic-updates InRelease [88.7 kB]\n",
            "Get:13 http://ppa.launchpad.net/marutter/c2d4u3.5/ubuntu bionic InRelease [15.4 kB]\n",
            "Get:14 http://archive.ubuntu.com/ubuntu bionic-backports InRelease [74.6 kB]\n",
            "Get:15 http://security.ubuntu.com/ubuntu bionic-security/universe amd64 Packages [794 kB]\n",
            "Get:16 http://ppa.launchpad.net/marutter/c2d4u3.5/ubuntu bionic/main Sources [1,742 kB]\n",
            "Get:17 http://archive.ubuntu.com/ubuntu bionic-updates/multiverse amd64 Packages [10.5 kB]\n",
            "Get:18 http://archive.ubuntu.com/ubuntu bionic-updates/restricted amd64 Packages [32.7 kB]\n",
            "Get:19 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 Packages [1,322 kB]\n",
            "Get:20 http://security.ubuntu.com/ubuntu bionic-security/main amd64 Packages [761 kB]\n",
            "Get:21 http://security.ubuntu.com/ubuntu bionic-security/multiverse amd64 Packages [6,781 B]\n",
            "Get:22 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 Packages [1,057 kB]\n",
            "Get:23 http://ppa.launchpad.net/marutter/c2d4u3.5/ubuntu bionic/main amd64 Packages [840 kB]\n",
            "Fetched 6,913 kB in 6s (1,166 kB/s)\n",
            "Reading package lists... Done\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "python-dev is already the newest version (2.7.15~rc1-1).\n",
            "g++ is already the newest version (4:7.4.0-1ubuntu2.3).\n",
            "g++ set to manually installed.\n",
            "python3-dev is already the newest version (3.6.7-1~18.04).\n",
            "The following package was automatically installed and is no longer required:\n",
            "  libnvidia-common-430\n",
            "Use 'apt autoremove' to remove it.\n",
            "The following additional packages will be installed:\n",
            "  fonts-dejavu-core fonts-dejavu-extra libatk-wrapper-java\n",
            "  libatk-wrapper-java-jni libxxf86dga1 openjdk-8-jre x11-utils\n",
            "Suggested packages:\n",
            "  openjdk-8-demo openjdk-8-source visualvm icedtea-8-plugin mesa-utils\n",
            "The following NEW packages will be installed:\n",
            "  fonts-dejavu-core fonts-dejavu-extra libatk-wrapper-java\n",
            "  libatk-wrapper-java-jni libxxf86dga1 openjdk-8-jdk openjdk-8-jre x11-utils\n",
            "0 upgraded, 8 newly installed, 0 to remove and 16 not upgraded.\n",
            "Need to get 5,091 kB of archives.\n",
            "After this operation, 13.4 MB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu bionic/main amd64 libxxf86dga1 amd64 2:1.1.4-1 [13.7 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu bionic/main amd64 fonts-dejavu-core all 2.37-1 [1,041 kB]\n",
            "Get:3 http://archive.ubuntu.com/ubuntu bionic/main amd64 fonts-dejavu-extra all 2.37-1 [1,953 kB]\n",
            "Get:4 http://archive.ubuntu.com/ubuntu bionic/main amd64 x11-utils amd64 7.7+3build1 [196 kB]\n",
            "Get:5 http://archive.ubuntu.com/ubuntu bionic/main amd64 libatk-wrapper-java all 0.33.3-20ubuntu0.1 [34.7 kB]\n",
            "Get:6 http://archive.ubuntu.com/ubuntu bionic/main amd64 libatk-wrapper-java-jni amd64 0.33.3-20ubuntu0.1 [28.3 kB]\n",
            "Get:7 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 openjdk-8-jre amd64 8u222-b10-1ubuntu1~18.04.1 [69.3 kB]\n",
            "Get:8 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 openjdk-8-jdk amd64 8u222-b10-1ubuntu1~18.04.1 [1,756 kB]\n",
            "Fetched 5,091 kB in 3s (1,902 kB/s)\n",
            "Selecting previously unselected package libxxf86dga1:amd64.\n",
            "(Reading database ... 134983 files and directories currently installed.)\n",
            "Preparing to unpack .../0-libxxf86dga1_2%3a1.1.4-1_amd64.deb ...\n",
            "Unpacking libxxf86dga1:amd64 (2:1.1.4-1) ...\n",
            "Selecting previously unselected package fonts-dejavu-core.\n",
            "Preparing to unpack .../1-fonts-dejavu-core_2.37-1_all.deb ...\n",
            "Unpacking fonts-dejavu-core (2.37-1) ...\n",
            "Selecting previously unselected package fonts-dejavu-extra.\n",
            "Preparing to unpack .../2-fonts-dejavu-extra_2.37-1_all.deb ...\n",
            "Unpacking fonts-dejavu-extra (2.37-1) ...\n",
            "Selecting previously unselected package x11-utils.\n",
            "Preparing to unpack .../3-x11-utils_7.7+3build1_amd64.deb ...\n",
            "Unpacking x11-utils (7.7+3build1) ...\n",
            "Selecting previously unselected package libatk-wrapper-java.\n",
            "Preparing to unpack .../4-libatk-wrapper-java_0.33.3-20ubuntu0.1_all.deb ...\n",
            "Unpacking libatk-wrapper-java (0.33.3-20ubuntu0.1) ...\n",
            "Selecting previously unselected package libatk-wrapper-java-jni:amd64.\n",
            "Preparing to unpack .../5-libatk-wrapper-java-jni_0.33.3-20ubuntu0.1_amd64.deb ...\n",
            "Unpacking libatk-wrapper-java-jni:amd64 (0.33.3-20ubuntu0.1) ...\n",
            "Selecting previously unselected package openjdk-8-jre:amd64.\n",
            "Preparing to unpack .../6-openjdk-8-jre_8u222-b10-1ubuntu1~18.04.1_amd64.deb ...\n",
            "Unpacking openjdk-8-jre:amd64 (8u222-b10-1ubuntu1~18.04.1) ...\n",
            "Selecting previously unselected package openjdk-8-jdk:amd64.\n",
            "Preparing to unpack .../7-openjdk-8-jdk_8u222-b10-1ubuntu1~18.04.1_amd64.deb ...\n",
            "Unpacking openjdk-8-jdk:amd64 (8u222-b10-1ubuntu1~18.04.1) ...\n",
            "Setting up fonts-dejavu-core (2.37-1) ...\n",
            "Setting up libxxf86dga1:amd64 (2:1.1.4-1) ...\n",
            "Setting up fonts-dejavu-extra (2.37-1) ...\n",
            "Setting up x11-utils (7.7+3build1) ...\n",
            "Setting up libatk-wrapper-java (0.33.3-20ubuntu0.1) ...\n",
            "Setting up libatk-wrapper-java-jni:amd64 (0.33.3-20ubuntu0.1) ...\n",
            "Setting up openjdk-8-jre:amd64 (8u222-b10-1ubuntu1~18.04.1) ...\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/jre/bin/policytool to provide /usr/bin/policytool (policytool) in auto mode\n",
            "Setting up openjdk-8-jdk:amd64 (8u222-b10-1ubuntu1~18.04.1) ...\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/appletviewer to provide /usr/bin/appletviewer (appletviewer) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/jconsole to provide /usr/bin/jconsole (jconsole) in auto mode\n",
            "Processing triggers for man-db (2.8.3-2ubuntu0.1) ...\n",
            "Processing triggers for hicolor-icon-theme (0.17-2) ...\n",
            "Processing triggers for fontconfig (2.12.6-0ubuntu2) ...\n",
            "Processing triggers for mime-support (3.60ubuntu1) ...\n",
            "Processing triggers for libc-bin (2.27-3ubuntu1) ...\n",
            "Collecting JPype1-py3\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9b/81/63f5e4202c598f362ee4684b41890f993d6e58309c5d90703f570ab85f62/JPype1-py3-0.5.5.4.tar.gz (88kB)\n",
            "\u001b[K     |████████████████████████████████| 92kB 2.9MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: JPype1-py3\n",
            "  Building wheel for JPype1-py3 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for JPype1-py3: filename=JPype1_py3-0.5.5.4-cp36-cp36m-linux_x86_64.whl size=2681748 sha256=4a5ed656ff1495272c17a05cd1169bec8f3fc35ba2e37e2f28bea07a47c26a71\n",
            "  Stored in directory: /root/.cache/pip/wheels/52/37/1f/1015d908d12a0e9b239543d031fda0cded9823aa1306939541\n",
            "Successfully built JPype1-py3\n",
            "Installing collected packages: JPype1-py3\n",
            "Successfully installed JPype1-py3-0.5.5.4\n",
            "Collecting konlpy\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/85/0e/f385566fec837c0b83f216b2da65db9997b35dd675e107752005b7d392b1/konlpy-0.5.2-py2.py3-none-any.whl (19.4MB)\n",
            "\u001b[K     |████████████████████████████████| 19.4MB 121kB/s \n",
            "\u001b[?25hCollecting beautifulsoup4==4.6.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9e/d4/10f46e5cfac773e22707237bfcd51bbffeaf0a576b0a847ec7ab15bd7ace/beautifulsoup4-4.6.0-py3-none-any.whl (86kB)\n",
            "\u001b[K     |████████████████████████████████| 92kB 6.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.6 in /usr/local/lib/python3.6/dist-packages (from konlpy) (1.17.4)\n",
            "Requirement already satisfied: lxml>=4.1.0 in /usr/local/lib/python3.6/dist-packages (from konlpy) (4.2.6)\n",
            "Collecting colorama\n",
            "  Downloading https://files.pythonhosted.org/packages/c9/dc/45cdef1b4d119eb96316b3117e6d5708a08029992b2fee2c143c7a0a5cc5/colorama-0.4.3-py2.py3-none-any.whl\n",
            "Collecting tweepy>=3.7.0\n",
            "  Downloading https://files.pythonhosted.org/packages/36/1b/2bd38043d22ade352fc3d3902cf30ce0e2f4bf285be3b304a2782a767aec/tweepy-3.8.0-py2.py3-none-any.whl\n",
            "Collecting JPype1>=0.7.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/07/09/e19ce27d41d4f66d73ac5b6c6a188c51b506f56c7bfbe6c1491db2d15995/JPype1-0.7.0-cp36-cp36m-manylinux2010_x86_64.whl (2.7MB)\n",
            "\u001b[K     |████████████████████████████████| 2.7MB 20.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tweepy>=3.7.0->konlpy) (1.3.0)\n",
            "Requirement already satisfied: PySocks>=1.5.7 in /usr/local/lib/python3.6/dist-packages (from tweepy>=3.7.0->konlpy) (1.7.1)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tweepy>=3.7.0->konlpy) (1.12.0)\n",
            "Requirement already satisfied: requests>=2.11.1 in /usr/local/lib/python3.6/dist-packages (from tweepy>=3.7.0->konlpy) (2.21.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib>=0.7.0->tweepy>=3.7.0->konlpy) (3.1.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests>=2.11.1->tweepy>=3.7.0->konlpy) (2019.11.28)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests>=2.11.1->tweepy>=3.7.0->konlpy) (1.24.3)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests>=2.11.1->tweepy>=3.7.0->konlpy) (2.8)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests>=2.11.1->tweepy>=3.7.0->konlpy) (3.0.4)\n",
            "Installing collected packages: beautifulsoup4, colorama, tweepy, JPype1, konlpy\n",
            "  Found existing installation: beautifulsoup4 4.6.3\n",
            "    Uninstalling beautifulsoup4-4.6.3:\n",
            "      Successfully uninstalled beautifulsoup4-4.6.3\n",
            "  Found existing installation: tweepy 3.6.0\n",
            "    Uninstalling tweepy-3.6.0:\n",
            "      Successfully uninstalled tweepy-3.6.0\n",
            "Successfully installed JPype1-0.7.0 beautifulsoup4-4.6.0 colorama-0.4.3 konlpy-0.5.2 tweepy-3.8.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dJbbAta148Tc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# NLTK 패키지를 이용하여 입력 텍스트를 N-gram 형태로 변환한다.\n",
        "sentence = \"나는 매일 아침 지하철을 탄다\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kvvfewcs5OR4",
        "colab_type": "code",
        "outputId": "3accf3be-569e-49fb-830e-d637cce58dd7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        }
      },
      "source": [
        "# NLTK 사용을 위하여 선행 패키지를 설치한다.\n",
        "nltk.download('punkt')\n",
        "\n",
        "# 입력 텍스트를 띄어쓰기 기준으로 토큰화한다.\n",
        "tokens = word_tokenize(sentence) "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fSAEP3U65nav",
        "colab_type": "code",
        "outputId": "4aabcad5-a640-43c1-a70d-1eb261794a61",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        }
      },
      "source": [
        "print(tokens)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['나는', '매일', '아침', '지하철을', '탄다']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jLTfZw_fcxhs",
        "colab_type": "code",
        "outputId": "09e44664-2b86-4838-ca72-a24aec8c572a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        }
      },
      "source": [
        "# 한국어의 단어는 띄어쓰기를 기준으로 하지 않기 때문에 konlpy를 이용해 형태소를 기준으로 토큰화한다.\n",
        "tagger = Okt()\n",
        "\n",
        "def tokenize(text):\n",
        "  tokens = ['/'.join(t) for t in tagger.pos(text)]\n",
        "  return tokens\n",
        "\n",
        "tokens = tokenize(sentence)\n",
        "print(tokens)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['나/Noun', '는/Josa', '매일/Noun', '아침/Noun', '지하철/Noun', '을/Josa', '탄다/Verb']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dgWgUE_N5yEf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 토큰을 N-gram의 형태로 바꾸어준다. \n",
        "# ngrams 함수의 두 번째 인자로 N값을 지정할 수 있다.\n",
        "bigram = ngrams(tokens, 2)\n",
        "trigram = ngrams(tokens, 3)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1FTnRG9O63WX",
        "colab_type": "code",
        "outputId": "f182814f-3870-406c-8a22-c171afae6106",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        }
      },
      "source": [
        "# N-gram을 출력해본다.\n",
        "print(\"bigram: \")\n",
        "for b in bigram:\n",
        "  print(b)\n",
        "\n",
        "print(\"\\ntrigram: \")\n",
        "for t in trigram:\n",
        "  print(t) "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "bigram: \n",
            "('나/Noun', '는/Josa')\n",
            "('는/Josa', '매일/Noun')\n",
            "('매일/Noun', '아침/Noun')\n",
            "('아침/Noun', '지하철/Noun')\n",
            "('지하철/Noun', '을/Josa')\n",
            "('을/Josa', '탄다/Verb')\n",
            "\n",
            "trigram: \n",
            "('나/Noun', '는/Josa', '매일/Noun')\n",
            "('는/Josa', '매일/Noun', '아침/Noun')\n",
            "('매일/Noun', '아침/Noun', '지하철/Noun')\n",
            "('아침/Noun', '지하철/Noun', '을/Josa')\n",
            "('지하철/Noun', '을/Josa', '탄다/Verb')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F0MpXv1H6_Gd",
        "colab_type": "code",
        "outputId": "94937940-2e6d-4350-dfb3-d8800b2b4ce1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 185
        }
      },
      "source": [
        "# padding을 통해 입력 데이터에 문장의 시작과 끝을 알리는 토큰을 추가한다. \n",
        "bigram = ngrams(tokens, 2, pad_left=True, pad_right=True, left_pad_symbol=\"<s>\", right_pad_symbol=\"</s>\")\n",
        "print(\"bigrams with padding: \")\n",
        "for b in bigram:\n",
        "  print(b)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "bigram with padding: \n",
            "('<s>', '나/Noun')\n",
            "('나/Noun', '는/Josa')\n",
            "('는/Josa', '매일/Noun')\n",
            "('매일/Noun', '아침/Noun')\n",
            "('아침/Noun', '지하철/Noun')\n",
            "('지하철/Noun', '을/Josa')\n",
            "('을/Josa', '탄다/Verb')\n",
            "('탄다/Verb', '</s>')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cr25hyHn9Shh",
        "colab_type": "code",
        "outputId": "4f1b26b9-5a25-4283-ab92-e4f3871a985e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        }
      },
      "source": [
        "# 문장 생성을 위하여 네이버 영화 리뷰 데이터셋을 다운로드한다.\n",
        "%%time\n",
        "!wget -nc -q https://raw.githubusercontent.com/e9t/nsmc/master/ratings_train.txt"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 38.8 ms, sys: 11.6 ms, total: 50.4 ms\n",
            "Wall time: 2.49 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TS64JsKs92Xi",
        "colab_type": "code",
        "outputId": "7d8d149a-ca02-42e5-c923-8e9edc3802e0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 131
        }
      },
      "source": [
        "# 다운로드 받은 데이터셋을 읽고 인덱스와 라벨을 제외한 텍스트 부분만 가져온다.\n",
        "# codecs 패키지는 대용량 파일을 조금씩 읽을 수 있게 해준다. \n",
        "\n",
        "with codecs.open(\"ratings_train.txt\", encoding='utf-8') as f:\n",
        "  data = [line.split('\\t') for line in f.read().splitlines()] # \\n 제외\n",
        "  data = data[1:] # header 제외\n",
        "print(\"데이터셋: \", data[:10])\n",
        "docs = [row[1] for row in data] # 텍스트 부분만 가져옴\n",
        "print(\"\\n텍스트 데이터:\", docs[:5])\n",
        "print(\"\\n문장 개수: \",len(docs)) # 총 15만개의 문장으로 이루어진 데이터셋임을 알 수 있다."
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "데이터셋:  [['9976970', '아 더빙.. 진짜 짜증나네요 목소리', '0'], ['3819312', '흠...포스터보고 초딩영화줄....오버연기조차 가볍지 않구나', '1'], ['10265843', '너무재밓었다그래서보는것을추천한다', '0'], ['9045019', '교도소 이야기구먼 ..솔직히 재미는 없다..평점 조정', '0'], ['6483659', '사이몬페그의 익살스런 연기가 돋보였던 영화!스파이더맨에서 늙어보이기만 했던 커스틴 던스트가 너무나도 이뻐보였다', '1'], ['5403919', '막 걸음마 뗀 3세부터 초등학교 1학년생인 8살용영화.ㅋㅋㅋ...별반개도 아까움.', '0'], ['7797314', '원작의 긴장감을 제대로 살려내지못했다.', '0'], ['9443947', '별 반개도 아깝다 욕나온다 이응경 길용우 연기생활이몇년인지..정말 발로해도 그것보단 낫겟다 납치.감금만반복반복..이드라마는 가족도없다 연기못하는사람만모엿네', '0'], ['7156791', '액션이 없는데도 재미 있는 몇안되는 영화', '1'], ['5912145', '왜케 평점이 낮은건데? 꽤 볼만한데.. 헐리우드식 화려함에만 너무 길들여져 있나?', '1']]\n",
            "\n",
            "텍스트 데이터: ['아 더빙.. 진짜 짜증나네요 목소리', '흠...포스터보고 초딩영화줄....오버연기조차 가볍지 않구나', '너무재밓었다그래서보는것을추천한다', '교도소 이야기구먼 ..솔직히 재미는 없다..평점 조정', '사이몬페그의 익살스런 연기가 돋보였던 영화!스파이더맨에서 늙어보이기만 했던 커스틴 던스트가 너무나도 이뻐보였다']\n",
            "\n",
            "문장 개수:  150000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XAd9C--T9_AP",
        "colab_type": "code",
        "outputId": "fa13fa39-e9f8-4d88-e123-3a6f6bdf561b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        }
      },
      "source": [
        "# 토큰화한 텍스트 데이터의 bigram을 모두 리스트에 추가한다.\n",
        "sentences = []\n",
        "for d in tqdm(docs):\n",
        "  tokens = tokenize(d)\n",
        "  bigram = ngrams(tokens, 2, pad_left=True, pad_right=True, left_pad_symbol=\"<s>\", right_pad_symbol=\"</s>\")\n",
        "  sentences += [t for t in bigram]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 150000/150000 [05:49<00:00, 429.55it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U_Pf91qqj9PH",
        "colab_type": "code",
        "outputId": "97922410-f2b5-4994-8168-ee56bd0de800",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 56
        }
      },
      "source": [
        "print(sentences[:10])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[('<s>', '아/Exclamation'), ('아/Exclamation', '더빙/Noun'), ('더빙/Noun', '../Punctuation'), ('../Punctuation', '진짜/Noun'), ('진짜/Noun', '짜증나네요/Adjective'), ('짜증나네요/Adjective', '목소리/Noun'), ('목소리/Noun', '</s>'), ('<s>', '흠/Noun'), ('흠/Noun', '.../Punctuation'), ('.../Punctuation', '포스터/Noun'), ('포스터/Noun', '보고/Noun'), ('보고/Noun', '초딩/Noun'), ('초딩/Noun', '영화/Noun'), ('영화/Noun', '줄/Noun'), ('줄/Noun', '..../Punctuation'), ('..../Punctuation', '오버/Noun'), ('오버/Noun', '연기/Noun'), ('연기/Noun', '조차/Josa'), ('조차/Josa', '가볍지/Adjective'), ('가볍지/Adjective', '않구나/Verb'), ('않구나/Verb', '</s>'), ('<s>', '너/Modifier'), ('너/Modifier', '무재/Noun'), ('무재/Noun', '밓었/Noun'), ('밓었/Noun', '다그/Noun'), ('다그/Noun', '래서/Noun'), ('래서/Noun', '보는것을/Verb'), ('보는것을/Verb', '추천/Noun'), ('추천/Noun', '한/Josa'), ('한/Josa', '다/Adverb')]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gL31DVi1ld25",
        "colab_type": "code",
        "outputId": "d85d0e9f-3eea-4156-c0bf-6dd4f1261d49",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        }
      },
      "source": [
        "cfd = ConditionalFreqDist(sentences)\n",
        "print(cfd[\"<s>\"].most_common(5))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[('정말/Noun', 2718), ('이/Noun', 2371), ('진짜/Noun', 2232), ('이/Determiner', 2115), ('영화/Noun', 2069)]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jYm2U1nhndI6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 주어진 토큰(c) 다음에 가장 많이 등장하는 n개의 단어를 반환하는 함수를 만든다.\n",
        "def most_common(c, n, pos=None):\n",
        "  if pos is None:\n",
        "    return cfd[tokenize(c)[0]].most_common(n)\n",
        "  else:\n",
        "    return cfd[\"/\".join([c, pos])].most_common(n)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "73MTcDKPoliE",
        "colab_type": "code",
        "outputId": "8b80ad0e-cd2a-4c56-adf0-78a3fb9e5b19",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 56
        }
      },
      "source": [
        "print(most_common(\"나\", 10))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[('는/Josa', 831), ('의/Josa', 339), ('만/Josa', 213), ('에게/Josa', 148), ('에겐/Josa', 84), ('랑/Josa', 81), ('한테/Josa', 50), ('참/Verb', 45), ('이/Determiner', 44), ('와도/Josa', 43)]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AaoisqGFnZaK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 단어별 등장 빈도를 기반으로 조건부 확률을 추정한다.\n",
        "cpd = ConditionalProbDist(cfd, MLEProbDist)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WrIUwvsOmv17",
        "colab_type": "code",
        "outputId": "c10b52a2-eaf6-43e1-b8b7-7c51fad1c3bf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        }
      },
      "source": [
        "# “.” 다음에 “</s>”가 올 확률을 출력한다.\n",
        "print(cpd[tokenize(\".\")[0]].prob(\"</s>\"))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.39102658679807606\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RPJO9Bw9sLcL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 토큰 c 다음에 토큰 w가 bigram으로 함께 등장할 확률을 구한다.\n",
        "def bigram_prob(c, w):\n",
        "  context = tokenize(c)[0]\n",
        "  word = tokenize(w)[0]\n",
        "  return cpd[context].prob(word)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5W56LrNYs6MO",
        "colab_type": "code",
        "outputId": "58610ee4-08f0-4cbe-d7a6-9a7d8fcacc67",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        }
      },
      "source": [
        "print(bigram_prob(\"이\", \"영화\"))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.4010748656417948\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "80QHPkHXs9qX",
        "colab_type": "code",
        "outputId": "6fae7357-5f9e-4ea4-d13f-9aec6f3d8f7c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        }
      },
      "source": [
        "print(bigram_prob(\"영화\", \"이\"))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.00015767585785521414\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jat3RD0LtJ8Z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 조건부 확률을 알게 되면 가장 확률이 높은 토큰열을 토대로 문장을 생성할 수 있다.\n",
        "def generate_sentence(seed=None, debug=False):\n",
        "  if seed is not None:\n",
        "    import random\n",
        "    random.seed(seed)\n",
        "  c = \"<s>\"\n",
        "  sentence = []\n",
        "  while True:\n",
        "    if c not in cpd:\n",
        "      break\n",
        "    w = cpd[c].generate()\n",
        "\n",
        "    if w == \"</s>\":\n",
        "      break\n",
        "    \n",
        "    word = w.split(\"/\")[0]\n",
        "    pos = w.split(\"/\")[1]\n",
        "\n",
        "    # 조사, 어미 등을 제외하고 각 토큰은 띄어쓰기로 구분하여 생성한다.\n",
        "    if c == \"<s>\":\n",
        "      sentence.append(word.title())\n",
        "    elif c in [\"`\", \"\\\"\",\"'\",\"(\"]:\n",
        "      sentence.append(word)\n",
        "    elif word in [\"'\", \".\", \",\", \")\", \":\", \";\", \"?\"]:\n",
        "      sentence.append(word)\n",
        "    elif pos in [\"Josa\", \"Punctuation\", \"Suffix\"]:\n",
        "        sentence.append(word)\n",
        "    elif w in [\"임/Noun\", \"것/Noun\", \"는걸/Noun\", \"릴때/Noun\",\n",
        "                \"되다/Verb\", \"이다/Verb\", \"하다/Verb\", \"이다/Adjective\"]:\n",
        "        sentence.append(word)\n",
        "    else:\n",
        "        sentence.append(\" \" + word)\n",
        "    c = w\n",
        "\n",
        "    if debug:\n",
        "      print(w)\n",
        "\n",
        "  return \"\".join(sentence)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pgWQJXqRuLMF",
        "colab_type": "code",
        "outputId": "2a218810-c33e-4ecf-ea42-87c4e5499f04",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 56
        }
      },
      "source": [
        "print(generate_sentence(2))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "도리까지 본 영화 너무... 뭔가.. 최고네요. 하지만.. 눈물 낫다는건 또 영화에 들지 않는다. 근데 뭐야 어떻게 그렇게 착했던 윤재랑은 에바 그린 드레스 소리 듣는거임\"\"\" 에리 욧의 미모로 합성 한 가수 노래와 흥행 놓친 영화다. 사투리 연기 하나 없는 ‘ 스피드 감 넘치는 스릴 넘치는 연기를 이해 되지 못 하시는 분보다 훨 재밌구만 평점을 망처 놓은 듯하다. 영화 보는이로 하여금 불편함을 느꼇을듯\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7RdPvL2AuLy8",
        "colab_type": "code",
        "outputId": "1d4f81c7-7e6f-406a-f024-2d6abfdc7cc3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "generate_sentence(2, debug=True)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "도리/Noun\n",
            "까지/Josa\n",
            "본/Verb\n",
            "영화/Noun\n",
            "너무/Adverb\n",
            ".../Punctuation\n",
            "뭔가/Noun\n",
            "../Punctuation\n",
            "최고/Noun\n",
            "네/Suffix\n",
            "요/Josa\n",
            "./Punctuation\n",
            "하지만/Conjunction\n",
            "../Punctuation\n",
            "눈물/Noun\n",
            "낫다는건/Verb\n",
            "또/Noun\n",
            "영화/Noun\n",
            "에/Josa\n",
            "들지/Verb\n",
            "않는다/Verb\n",
            "./Punctuation\n",
            "근데/Adverb\n",
            "뭐/Noun\n",
            "야/Josa\n",
            "어떻게/Adjective\n",
            "그렇게/Adverb\n",
            "착했던/Adjective\n",
            "윤재/Noun\n",
            "랑은/Josa\n",
            "에바/Noun\n",
            "그린/Noun\n",
            "드레스/Noun\n",
            "소리/Noun\n",
            "듣는거/Verb\n",
            "임/Noun\n",
            "\"\"\"/Punctuation\n",
            "에리/Noun\n",
            "욧의/Noun\n",
            "미모/Noun\n",
            "로/Josa\n",
            "합성/Noun\n",
            "한/Determiner\n",
            "가수/Noun\n",
            "노래/Noun\n",
            "와/Josa\n",
            "흥행/Noun\n",
            "놓친/Verb\n",
            "영화/Noun\n",
            "다/Josa\n",
            "./Punctuation\n",
            "사투리/Noun\n",
            "연기/Noun\n",
            "하나/Noun\n",
            "없는/Adjective\n",
            "‘/Foreign\n",
            "스피드/Noun\n",
            "감/Noun\n",
            "넘치는/Adjective\n",
            "스릴/Noun\n",
            "넘치는/Adjective\n",
            "연기/Noun\n",
            "를/Josa\n",
            "이해/Noun\n",
            "되지/Verb\n",
            "못/VerbPrefix\n",
            "하시는/Verb\n",
            "분/Noun\n",
            "보다/Josa\n",
            "훨/Noun\n",
            "재밌구만/Adjective\n",
            "평점/Noun\n",
            "을/Josa\n",
            "망처/Noun\n",
            "놓은/Verb\n",
            "듯/Noun\n",
            "하다/Verb\n",
            "./Punctuation\n",
            "영화/Noun\n",
            "보는이로/Verb\n",
            "하여금/Adverb\n",
            "불편함을/Adjective\n",
            "느꼇을듯/Noun\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'도리까지 본 영화 너무... 뭔가.. 최고네요. 하지만.. 눈물 낫다는건 또 영화에 들지 않는다. 근데 뭐야 어떻게 그렇게 착했던 윤재랑은 에바 그린 드레스 소리 듣는거임\"\"\" 에리 욧의 미모로 합성 한 가수 노래와 흥행 놓친 영화다. 사투리 연기 하나 없는 ‘ 스피드 감 넘치는 스릴 넘치는 연기를 이해 되지 못 하시는 분보다 훨 재밌구만 평점을 망처 놓은 듯하다. 영화 보는이로 하여금 불편함을 느꼇을듯'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 72
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6wV8yp-J2U5j",
        "colab_type": "text"
      },
      "source": [
        "### 5. 결과\n",
        "： 위 예제는 코퍼스 내의 등장 빈도에 기반하여 문장을 생성한다. bigram 언어 모델로 생성한 것이기 때문에 인접한 두 단어는 그나마 자연스럽지만 멀리 떨어진 단어와는 전혀 무관한 모습을 보인다. 또한 생성된 문장의 전체적인 문맥이 부자연스러우며 통사적으로 부적절한 모습도 보인다. 이는 코퍼스 내의 정보만으로 제한된 단어 조합만을 고려하는 N-gram 언어 모델의 한계로 보인다. 위 예제는 단순화를 위해 전처리와 규칙 처리를 최소화하였는데, 데이터셋을 늘리고 한국어 특징에 맞게 전처리를 진행한다면 보다 향상된 결과를 얻을 수 있을 것이다.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BaSov8sY2w1s",
        "colab_type": "text"
      },
      "source": [
        "<참고>\n",
        "\n",
        "> https://datascienceschool.net/view-notebook/a0c848e1e2d343d685e6077c35c4203b/\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T8lEfVvr2x7z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}